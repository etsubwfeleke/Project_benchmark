title,body,labels,milestone
"Finalize LLM backends","Select OpenAI + Gemini as final model backends.","milestone-2,code","2"
"Set up API keys","Configure API credentials and secure storage.","milestone-2,code","2"
"Design synthetic tasks","Use DeepEval and LLMs to generate synthetic benchmark scenarios.","milestone-2,data","2"
"Design real-world inspired tasks","Create tasks around summarization, quiz generation, retrieval.","milestone-2,data","2"
"Define gold end states","Specify expected outputs for benchmark tasks.","milestone-2,data","2"
"Define oracle plans","Specify ideal task execution steps.","milestone-2,data","2"
"Organize tasks format","Structure tasks in JSON/YAML/Python dicts.","milestone-2,data","2"
"Document task/model decisions","Explain why specific tasks and models were chosen.","milestone-2,docs","2"
"Build benchmark harness","Develop reproducible Python evaluation framework.","milestone-3,code","3"
"Implement sandbox","Create deterministic safe environment for tool calls.","milestone-3,code,safety","3"
"Run seed tasks","Validate harness by running small set of tasks.","milestone-3,code","3"
"Verify reproducibility","Ensure same input â†’ same output.","milestone-3,code","3"
"Implement No-Tool agent","Develop baseline agent without external tools.","milestone-3,code","3"
"Implement Single-Tool agent","Develop agent using search tool.","milestone-3,code","3"
"Implement Multi-Tool agent","Develop agent using summarizer + quiz generator.","milestone-3,code","3"
"Run all tasks","Execute all scenarios across agents.","milestone-3,code","3"
"Collect evaluation metrics","Gather success rate, efficiency, latency, cost.","milestone-3,code","3"
"Generate comparison table","Create results table comparing all agents.","milestone-3,docs","3"
"Ablation studies","Experiment with different prompts and tool setups.","milestone-3,code","3"
"Adversarial: prompt injection","Test resilience against prompt injection.","milestone-3,safety","3"
"Adversarial: tool misuse","Test resilience against tool misuse.","milestone-3,safety","3"
"Adversarial: data exfiltration","Test resilience against sensitive info extraction.","milestone-3,safety","3"
"Document robustness findings","Summarize robustness and alignment test results.","milestone-3,docs","3"
"Aggregate final results","Compile overall experiment results.","milestone-4,code","4"
"Write final report","Document methods, results, discussion.","milestone-4,docs","4"
"Prepare presentation","Design slides with visual comparisons.","milestone-4,docs","4"
"Clean repo","Add README, docstrings, comments, cleanup.","milestone-4,docs","4"
"Publish repo","Make GitHub repository public.","milestone-4,docs","4"
"Write blog post","Draft blog: Benchmarking OpenAI vs Gemini.","milestone-4,blog","4"
"Submit deliverables","Turn in final report, slides, repo.","milestone-4,docs","4"
"Create requirements.txt","Add project dependencies.","general,code",""
"Add .gitignore","Standard Python ignores.","general,code",""
"Add LICENSE","Choose open-source license.","general,docs",""
"Add docs/ folder","Documentation space for project.","general,docs",""
"Add tasks/ folder","Folder to store benchmark task definitions.","general,data",""
"Add src/ folder","Source code folder for harness.","general,code",""
"Add references","Include resources in README.","general,docs",""
