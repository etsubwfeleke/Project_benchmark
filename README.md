# Project_benchmark
Auto Bench: A reproducible benchmark suite for evaluating agentic LLMs (OpenAI &amp; Gemini) across no-tool, single-tool, and multi-tool configurations. Includes 40+ task scenarios, evaluation harness, safety tests, and comparative performance analysis.
